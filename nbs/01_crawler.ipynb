{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crawler\n",
    "\n",
    "> crawler with call backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from pw.core import  *\n",
    "from pw.helper import *\n",
    "from operator import attrgetter\n",
    "import inspect\n",
    "from fastcore.all import *\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "#| hide\n",
    "class Callback(): order = 0\n",
    "\n",
    "async def run_cbs(cbs, method_nm, crawler=None, *args, **kwargs):\n",
    "    for cb in sorted(cbs, key=attrgetter('order')):\n",
    "        method = getattr(cb, method_nm, None)\n",
    "        if method :\n",
    "            if inspect.iscoroutinefunction(method):\n",
    "                await method(crawler, *args, **kwargs)\n",
    "            else:\n",
    "                method(crawler, *args, **kwargs)\n",
    "\n",
    "class with_cbs:\n",
    "    def __init__(self, nm): self.nm = nm\n",
    "    def __call__(self, f):\n",
    "        def _f(o, *args, **kwargs):\n",
    "            try:\n",
    "                o.callback(f'before_{self.nm}')\n",
    "                print(self.nm)\n",
    "                f(o, *args, **kwargs)\n",
    "                o.callback(f'after_{self.nm}')\n",
    "            except globals()[f'Cancel{self.nm.title()}Exception']: pass\n",
    "            finally: o.callback(f'cleanup_{self.nm}')\n",
    "        return _f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawler with Callback System\n",
    "\n",
    "This crawler implements a flexible web scraping system with callback hooks for extensibility, inspired by fastai's [callback system](https://docs.fast.ai/callback.core.html).<br>\n",
    "![image](flow.png)\n",
    "## Architecture\n",
    "The crawler operates with two main callback hooks: `before_visit` and `after_visit`, with an `ord` parameter controlling execution order.\n",
    "\n",
    "## Key Features\n",
    "1. **Parallel Processing**: \n",
    "   - Configurable number of pages (`np`) for concurrent processing\n",
    "   - Efficient browser resource management\n",
    "\n",
    "2. **URL Management**:\n",
    "   - Input: List of URLs to visit (`to_visit`)\n",
    "   - Tracks progress through callback-accessible sets:\n",
    "     - `visited`: Already processed URLs\n",
    "     - `unvisited`: Pending URLs\n",
    "     - `visit_window`: Current batch of URLs (size = `np`)\n",
    "\n",
    "3. **Callback System**:\n",
    "   - Extensible through custom callbacks\n",
    "   - Ordered execution (`ord`)\n",
    "   - Full access to crawler state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Crawl():\n",
    "    def __init__(self, np: int = 1, to_visit: Optional[List[str]] = None, cbs=None): # type: ignore\n",
    "        self.np = np\n",
    "        self.visited = set()\n",
    "        self.unvisited = set(to_visit)\n",
    "        self.cbs = L(cbs)\n",
    "        \n",
    "    async def one_visit(self, idx):\n",
    "        page = self.pages[idx]\n",
    "        \n",
    "        await self.callback('before_visit',idx)\n",
    "        \n",
    "        await page.goto(self.visit_window[idx])\n",
    "        await page.wait()\n",
    "\n",
    "        await self.callback('after_visit', idx)\n",
    "        \n",
    "    async def run(self, stealth: bool = False, **kwargs):\n",
    "        async with setup_browser(n=self.np, stealth = stealth, **kwargs) as obj:\n",
    "            if obj.is_valid:\n",
    "                    self.pages, self.brow, self.ctx = obj.pages, obj.brow, obj.ctx\n",
    "\n",
    "                    while self.unvisited:\n",
    "                        self.visit_window = list(self.unvisited - self.visited)[:self.np] #not visited \n",
    "                        if len(self.visit_window) == 0: break\n",
    "                        tasks = [self.one_visit(i) for i in range(len(self.visit_window)) ]\n",
    "                    \n",
    "                        await asyncio.gather(*tasks)  \n",
    "                        visited_urls = set(self.visit_window)\n",
    "                        self.unvisited.difference_update(visited_urls) # remove the urls from the to_visit\n",
    "                        \n",
    "                        self.visited.update(visited_urls)\n",
    "                        \n",
    "    def __getattr__(self, name):\n",
    "        if name.startswith('before_') or name.startswith('after_'): return partial(self.callback, name)\n",
    "        raise AttributeError(name)\n",
    "\n",
    "    async def callback(self, method_nm, *args, **kwargs ): \n",
    "        await run_cbs(self.cbs, method_nm, self, *args, **kwargs)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ \n",
      "before_visit  idx=0\n",
      "before_visit  idx=0\n",
      "before_visit  idx=0\n",
      "before_visit  idx=0\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "class CB(Callback):\n",
    "    def __init__(self):\n",
    "        print(f\"__init__ \" )\n",
    "\n",
    "    def before_visit(self, crawler, idx):\n",
    "        print(f\"before_visit  {idx=}\" )\n",
    "\n",
    "    def after_visit(self, crawler, idx):\n",
    "        print(f\"before_visit  {idx=}\" )\n",
    "\n",
    "C = Crawl(1, ['https://solveit.fast.ai/', 'https://fastcore.fast.ai/'], [CB()])\n",
    "await C.run(headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ \n",
      "before_visit  idx=0\n",
      "before_visit  idx=1\n",
      "before_visit  idx=0\n",
      "before_visit  idx=1\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "C = Crawl(2, ['https://solveit.fast.ai/', 'https://fastcore.fast.ai/'], [CB()])\n",
    "await C.run(headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __callback__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract text for a given `xpath`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetTextCB(Callback):\n",
    "    \n",
    "\n",
    "    async def after_visit(self, crawler, idx):\n",
    "        if crawler.pages[idx].url == 'https://fastcore.fast.ai/':\n",
    "            loc = await crawler.pages[idx].find_ele('//span[contains(text(), \"Welcome to fastcore\")]')\n",
    "            if loc:\n",
    "                assert await loc[0].get_text() == \"Welcome to fastcore\"\n",
    "\n",
    "C = Crawl(2, ['https://solveit.fast.ai/', 'https://fastcore.fast.ai/'], [GetTextCB()])\n",
    "await C.run(headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To traverse all webpages within the same domain using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TraveseSameDomainCB(Callback):\n",
    "    \"\"\"\n",
    "    Callback helping traveling all the links available in the same domain.\n",
    "    \"\"\"\n",
    "    def __init__(self, url):\n",
    "        self.base_domain = domain(url)\n",
    "        self.order = 1\n",
    "    \n",
    "    async def after_visit(self, crawler, idx):\n",
    "        url = crawler.pages[idx].url\n",
    "        if domain(url) == self.base_domain:\n",
    "\n",
    "            links = await find_all_links(crawler.pages[idx])\n",
    "\n",
    "            if links:\n",
    "                links = [i for i in links if self.base_domain == domain(i) and not is_same_resource(url, i) ]\n",
    "                links = {i for i in links if not any ( j in i for j in IGNORE_EXT)}\n",
    "                links.difference_update(crawler.visited)\n",
    "                \n",
    "                crawler.unvisited.update(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://solveit.fast.ai/'\n",
    "C = Crawl(5, [url], [TraveseSameDomainCB(url)])\n",
    "await C.run(headless=True)\n",
    "assert all([domain(i)==domain(url) for i in C.visited])\n",
    "assert len(C.unvisited) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl a url and save in md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ToMDCB(Callback):\n",
    "    \"\"\"\n",
    "    Callback helping traveling all the links available in the same domain.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dir=\"PW\"):\n",
    "        self.order = 2\n",
    "        self.base_dir = base_dir \n",
    "    \n",
    "    async def after_visit(self, crawler, idx):\n",
    "        url = crawler.pages[idx].url\n",
    "        P = Path(f\"{self.base_dir}/{url2fn(url)}\")\n",
    "        P.mkdir(exist_ok=True, parents=True)\n",
    "        fn = P/'index.md'\n",
    "        print(f\"writing to {fn=}\")\n",
    "        md_str = await crawler.pages[idx].h2md()\n",
    "        #print_md(md_str)\n",
    "        fn.write_text(md_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to fn=Path('PW/solveit_fast_ai/index.md')\n",
      "writing to fn=Path('PW/solveit_fast_ai_privacy/index.md')\n",
      "writing to fn=Path('PW/solveit_fast_ai_course_info/index.md')\n",
      "writing to fn=Path('PW/solveit_fast_ai_terms/index.md')\n",
      "writing to fn=Path('PW/solveit_fast_ai_learn_more/index.md')\n"
     ]
    }
   ],
   "source": [
    "url = 'https://solveit.fast.ai/'\n",
    "C = Crawl(3, [url], [TraveseSameDomainCB(url), ToMDCB()])\n",
    "await C.run(headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
